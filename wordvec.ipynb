{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Embedding, LeakyReLU, \\\n",
    "                        Merge, concatenate, Input, BatchNormalization\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.utils import shuffle\n",
    "import keras\n",
    "import gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arun/Programs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n",
      "/home/arun/Programs/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "trainvar = pd.read_csv('training_variants')\n",
    "traintex = pd.read_csv('training_text', sep='\\|\\|', header=None, names=['ID','Text'], skiprows=[0])\n",
    "train = pd.merge(trainvar, traintex, on='ID')\n",
    "\n",
    "trainvar = pd.read_csv('test_variants')\n",
    "traintex = pd.read_csv('test_text', sep='\\|\\|', header=None, names=['ID','Text'], skiprows=[0])\n",
    "test = pd.merge(trainvar, traintex, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Text = train.Gene +' '+ train.Variation +' '+ train.Text\n",
    "test.Text = test.Gene + test.Variation + test.Text\n",
    "train.Text = train.Text.str.lower()\n",
    "test.Text = test.Text.str.lower()\n",
    "for words in stopwords.words('english'):\n",
    "    test.Text = test.Text.str.replace(' '+words+' ', '')\n",
    "    train.Text = train.Text.str.replace(' '+words+' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintext = test.Text.tolist()+train.Text.tolist()\n",
    "sentences = []\n",
    "for t in traintext:\n",
    "    #for s in sent_tokenize(t):\n",
    "    sentences.append(text.text_to_word_sequence(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlength=10000\n",
    "vec_size=50\n",
    "vectorizer = gensim.models.Word2Vec(sentences, size=vec_size, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(train['Class']-1, num_classes=9)\n",
    "tok = text.Tokenizer()\n",
    "tok.fit_on_texts(train['Text'])\n",
    "X = tok.texts_to_sequences(train['Text'])\n",
    "X = sequence.pad_sequences(X ,maxlen=maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros(shape=(len(tok.word_index)+1,vec_size))\n",
    "for k, v in tok.word_index.items():\n",
    "    if k in vectorizer.wv.vocab:\n",
    "        weights[v] = vectorizer.wv[k]      \n",
    "weights = weights/np.amax(abs(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 5000, 50)          58864600  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 4991, 128)         64128     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4991, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 2495, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2495, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 2486, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2486, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1243, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 159104)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               20365440  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 9)                 1161      \n",
      "=================================================================\n",
      "Total params: 79,460,833\n",
      "Trainable params: 79,460,065\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(max(tok.word_index.values())+1, 15, input_length=maxlength))\n",
    "# model.add(Conv1D(128,10,activation='relu'))\n",
    "# model.add(MaxPooling1D())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(128,10,activation='relu'))\n",
    "# model.add(MaxPooling1D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128,activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(units=9,activation='softmax'))\n",
    "\n",
    "\n",
    "input1 = Input(shape=(maxlength,))\n",
    "x = Embedding(max(tok.word_index.values())+1, vec_size, input_length=maxlength, weights=[weights])(input1)\n",
    "x = Conv1D(128,10, activation='relu')(x)\n",
    "#x = LeakyReLU(0.1)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(128,10, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "#x = LeakyReLU(0.1)(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128)(x)\n",
    "x = LeakyReLU(0.1)(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(units=9, activation='softmax')(x)\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3154 samples, validate on 167 samples\n",
      "Epoch 1/3\n",
      "3154/3154 [==============================] - 296s - loss: 0.7557 - acc: 0.7698 - val_loss: 2.9888 - val_acc: 0.1796\n",
      "Epoch 2/3\n",
      "3154/3154 [==============================] - 296s - loss: 0.5201 - acc: 0.8272 - val_loss: 2.7476 - val_acc: 0.1916\n",
      "Epoch 3/3\n",
      "3154/3154 [==============================] - 298s - loss: 0.4251 - acc: 0.8386 - val_loss: 2.5201 - val_acc: 0.1796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe370e1ef60>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size=128, epochs=3, verbose=1, validation_split=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3321/3321 [==============================] - 299s - loss: 0.5344 - acc: 0.8193    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe381003630>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('wordvec.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tok.texts_to_sequences(test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5668/5668 [==============================] - 193s   \n"
     ]
    }
   ],
   "source": [
    "classes = model.predict(sequence.pad_sequences(x,maxlen=maxlength), batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "      <th>class3</th>\n",
       "      <th>class4</th>\n",
       "      <th>class5</th>\n",
       "      <th>class6</th>\n",
       "      <th>class7</th>\n",
       "      <th>class8</th>\n",
       "      <th>class9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.643345e-11</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>1.044639e-06</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.991706</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.862521e-10</td>\n",
       "      <td>0.007780</td>\n",
       "      <td>2.613663e-06</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.982644</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4.481734e-11</td>\n",
       "      <td>0.004419</td>\n",
       "      <td>8.306049e-07</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.992622</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4.760287e-11</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>8.806072e-07</td>\n",
       "      <td>0.001826</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.993619</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.154017e-10</td>\n",
       "      <td>0.005105</td>\n",
       "      <td>1.252988e-06</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.989428</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>7.590027e-10</td>\n",
       "      <td>0.008389</td>\n",
       "      <td>2.254199e-06</td>\n",
       "      <td>0.009819</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.980769</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>3.427970e-10</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>1.724295e-06</td>\n",
       "      <td>0.005370</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.986385</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.556621e-10</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>1.391429e-06</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.988077</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4.765874e-10</td>\n",
       "      <td>0.007517</td>\n",
       "      <td>2.027721e-06</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.985914</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>3.491654e-11</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>7.190160e-07</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.992822</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3.222343e-11</td>\n",
       "      <td>0.005096</td>\n",
       "      <td>7.929431e-07</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.993028</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>4.474139e-11</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>8.344489e-07</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.993301</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5.059624e-10</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>2.114894e-06</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.985520</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>8.432784e-11</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>9.701967e-07</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.992403</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3.466081e-11</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>7.906550e-07</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.992819</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID        class1    class2        class3    class4    class5    class6  \\\n",
       "0    0  7.643345e-11  0.006044  1.044639e-06  0.001856  0.000319  0.000004   \n",
       "1    1  7.862521e-10  0.007780  2.613663e-06  0.008557  0.000815  0.000013   \n",
       "2    2  4.481734e-11  0.004419  8.306049e-07  0.002551  0.000338  0.000003   \n",
       "3    3  4.760287e-11  0.004211  8.806072e-07  0.001826  0.000274  0.000003   \n",
       "4    4  1.154017e-10  0.005105  1.252988e-06  0.004873  0.000491  0.000004   \n",
       "5    5  7.590027e-10  0.008389  2.254199e-06  0.009819  0.000836  0.000014   \n",
       "6    6  3.427970e-10  0.007531  1.724295e-06  0.005370  0.000581  0.000008   \n",
       "7    7  1.556621e-10  0.006554  1.391429e-06  0.004764  0.000501  0.000005   \n",
       "8    8  4.765874e-10  0.007517  2.027721e-06  0.005835  0.000581  0.000010   \n",
       "9    9  3.491654e-11  0.005038  7.190160e-07  0.001779  0.000300  0.000002   \n",
       "10  10  3.222343e-11  0.005096  7.929431e-07  0.001480  0.000337  0.000002   \n",
       "11  11  4.474139e-11  0.004236  8.344489e-07  0.002090  0.000304  0.000002   \n",
       "12  12  5.059624e-10  0.008163  2.114894e-06  0.005299  0.000859  0.000011   \n",
       "13  13  8.432784e-11  0.004877  9.701967e-07  0.002337  0.000310  0.000003   \n",
       "14  14  3.466081e-11  0.005183  7.906550e-07  0.001633  0.000302  0.000003   \n",
       "\n",
       "      class7    class8    class9  \n",
       "0   0.991706  0.000001  0.000069  \n",
       "1   0.982644  0.000004  0.000184  \n",
       "2   0.992622  0.000001  0.000066  \n",
       "3   0.993619  0.000001  0.000066  \n",
       "4   0.989428  0.000002  0.000096  \n",
       "5   0.980769  0.000004  0.000167  \n",
       "6   0.986385  0.000003  0.000120  \n",
       "7   0.988077  0.000002  0.000096  \n",
       "8   0.985914  0.000003  0.000138  \n",
       "9   0.992822  0.000001  0.000057  \n",
       "10  0.993028  0.000001  0.000055  \n",
       "11  0.993301  0.000001  0.000065  \n",
       "12  0.985520  0.000004  0.000142  \n",
       "13  0.992403  0.000001  0.000068  \n",
       "14  0.992819  0.000001  0.000058  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols=['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9']\n",
    "dfsub = pd.DataFrame(classes, columns=cols)\n",
    "dfsub.insert(0,'ID',range(len(dfsub.class1)))\n",
    "dfsub.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsub.to_csv('wordvec.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
