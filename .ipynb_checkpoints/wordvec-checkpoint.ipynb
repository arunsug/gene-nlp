{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Embedding, LeakyReLU, Merge, concatenate, Input\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from keras.preprocessing import text, sequence\n",
    "from sklearn.utils import shuffle\n",
    "import keras\n",
    "import gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainvar = pd.read_csv('training_variants')\n",
    "traintex = pd.read_csv('training_text', sep='\\|\\|', header=None, names=['ID','Text'], skiprows=[0])\n",
    "train = pd.merge(trainvar, traintex, on='ID')\n",
    "\n",
    "trainvar = pd.read_csv('test_variants')\n",
    "traintex = pd.read_csv('test_text', sep='\\|\\|', header=None, names=['ID','Text'], skiprows=[0])\n",
    "test = pd.merge(trainvar, traintex, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Text = train.Text.str.lower()\n",
    "test.Text = test.Text.str.lower()\n",
    "train.Text = train.Gene +' '+ train.Variation +' '+ train.Text\n",
    "test.Text = test.Gene + test.Variation + test.Text\n",
    "l = stopwords.words('english').append(['well','determine'])\n",
    "for words in stopwords.words('english'):\n",
    "    test.Text = test.Text.str.replace(' '+words+' ', '')\n",
    "    train.Text = train.Text.str.replace(' '+words+' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlength=10000\n",
    "y = keras.utils.to_categorical(train['Class']-1, num_classes=9)\n",
    "tok = text.Tokenizer()\n",
    "tok.fit_on_texts(train['Text'])\n",
    "X = tok.texts_to_sequences(train['Text'])\n",
    "X = sequence.pad_sequences(X ,maxlen=maxlength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(max(tok.word_index.values())+1, 15, input_length=maxlength))\n",
    "# model.add(Conv1D(128,10,activation='relu'))\n",
    "# model.add(MaxPooling1D())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(128,10,activation='relu'))\n",
    "# model.add(MaxPooling1D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128,activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(units=9,activation='softmax'))\n",
    "\n",
    "\n",
    "input1 = Input(shape=(maxlength,))\n",
    "x = Embedding(max(tok.word_index.values())+1, 15, input_length=maxlength)(input1)\n",
    "x = Conv1D(128,10, activation='relu')(x)\n",
    "#x = LeakyReLU(0.1)(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(128,10, activation='relu')(x)\n",
    "#x = LeakyReLU(0.1)(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = LeakyReLU(0.1)(x)\n",
    "       \n",
    "output = Dense(units=9, activation='softmax')(x)\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size=128, epochs=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tok.texts_to_sequences(test['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = model.predict(sequence.pad_sequences(x,maxlen=maxlength), batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = np.zeros_like(classes)\n",
    "for i in range(len(classes)):\n",
    "    cl[i, classes[i].argmax()] = 1\n",
    "cols=['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9']\n",
    "dfsub = pd.DataFrame(classes, columns=cols)\n",
    "dfsub.insert(0,'ID',range(len(dfsub.class1)))\n",
    "dfsub.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsub.to_csv('embtry.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
