{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D, Embedding, LeakyReLU, Merge, concatenate, Input, BatchNormalization\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from keras.preprocessing import text, sequence\n",
    "import keras\n",
    "import gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainvar = pd.read_csv('training_variants')\n",
    "traintex = pd.read_csv('training_text', sep='\\|\\|', header=None, names=['ID','Text'], skiprows=[0])\n",
    "train = pd.merge(trainvar, traintex, on='ID')\n",
    "\n",
    "trainvar = pd.read_csv('test_variants')\n",
    "traintex = pd.read_csv('test_text', sep='\\|\\|', header=None, names=['ID','Text'], skiprows=[0])\n",
    "test = pd.merge(trainvar, traintex, on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traintext = test.Text.tolist()+train.Text.tolist()\n",
    "sentences = []\n",
    "for t in traintext:\n",
    "    for s in sent_tokenize(t):\n",
    "        sentences.append(word_tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_size=50\n",
    "vectorizer = gensim.models.Word2Vec(sentences, size=vec_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.Text = train.Gene +' '+ train.Variation +' '+ train.Text\n",
    "test.Text = test.Gene + test.Variation + test.Text\n",
    "train.Text = train.Text.str.lower()\n",
    "test.Text = test.Text.str.lower()\n",
    "l = stopwords.words('english').append(['well','determine'])\n",
    "for words in stopwords.words('english'):\n",
    "    test.Text = test.Text.str.replace(' '+words+' ', '')\n",
    "    train.Text = train.Text.str.replace(' '+words+' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlength=10000\n",
    "\n",
    "m=0\n",
    "for g in train.Gene:\n",
    "    if len(g) > m:\n",
    "        m=len(g)\n",
    "for g in test.Gene:\n",
    "    if len(g) > m:\n",
    "        m=len(g)\n",
    "genelength = m\n",
    "genelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "A = ord('A')\n",
    "def geneVec(gene):\n",
    "    array = np.zeros((genelength, 36))\n",
    "    i=0\n",
    "    \n",
    "    for c in gene:\n",
    "        if c.isdigit():\n",
    "            array[i,int(c)] = 1\n",
    "        else:\n",
    "            array[i,10+ord(c)-A]=1\n",
    "        i += 1\n",
    "    return array\n",
    "\n",
    "train.Gene = train.Gene.str.upper()\n",
    "test.Gene = test.Gene.str.upper()\n",
    "\n",
    "train = train.assign(genevec = [ geneVec(g) for g in train.Gene])\n",
    "test = test.assign(genevec = [ geneVec(g) for g in test.Gene])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = keras.utils.to_categorical(train['Class']-1, num_classes=9)\n",
    "tok = text.Tokenizer()\n",
    "tok.fit_on_texts(train['Text'])\n",
    "X = tok.texts_to_sequences(train.Text)\n",
    "X = [sequence.pad_sequences(X ,maxlen=maxlength),np.stack(train.genevec.tolist(),axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = np.zeros(shape=(len(tok.word_index)+1,vec_size))\n",
    "for k, v in tok.word_index.items():\n",
    "    if k in vectorizer.wv.vocab:\n",
    "        weights[v] = vectorizer.wv[k]      \n",
    "weights = weights/np.amax(abs(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Embedding(max(tok.word_index.values())+1, 15, input_length=maxlength))\n",
    "# model.add(Conv1D(128,10))\n",
    "# model.add(LeakyReLU(0.1))\n",
    "# model.add(MaxPooling1D())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Conv1D(128,10))\n",
    "# model.add(LeakyReLU(0.1))\n",
    "# model.add(MaxPooling1D())\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(128))\n",
    "# model.add(LeakyReLU(0.1))\n",
    "# model2 = Sequential()\n",
    "# model2.add(Conv1D(15,3, input_shape=(genelength,36)))\n",
    "# model2.add(LeakyReLU(0.1))\n",
    "# model2.add(MaxPooling1D())\n",
    "# model2.add(Flatten())\n",
    "# model2.add(Dense(32))\n",
    "# model2.add(LeakyReLU(0.1))\n",
    "           \n",
    "# model = Sequential()\n",
    "# model.add(Concatenate([model1,model2]))\n",
    "# model.add(Dense(units=9, activation='softmax'))\n",
    "# model.summary()\n",
    "\n",
    "input1 = Input(shape=(maxlength,))\n",
    "x = Embedding(max(tok.word_index.values())+1, 100, input_length=maxlength,weights=[weights])(input1)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv1D(128,10, activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(128,10, activation='relu')(x)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128)(x)\n",
    "words = LeakyReLU(0.1)(x)\n",
    "\n",
    "input2 = Input(shape=(genelength,36,))\n",
    "x = Conv1D(15,2,activation='relu')(input2)\n",
    "x = MaxPooling1D()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(32,activation='relu')(x)\n",
    "x = Dense(genelength)(x)\n",
    "gene = LeakyReLU(0.1)(x)\n",
    "           \n",
    "x = concatenate([words,gene])\n",
    "output = Dense(units=9, activation='softmax')(x)\n",
    "          \n",
    "model = Model(inputs=[input1,input2], outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X, y, batch_size=128, epochs=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tok.texts_to_sequences(test['Text'])\n",
    "x = [sequence.pad_sequences(x,maxlen=maxlength),np.stack(test.genevec.tolist(),axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = model.predict(x, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl = np.zeros_like(classes)\n",
    "for i in range(len(classes)):\n",
    "    cl[i, classes[i].argmax()] = 1\n",
    "cols=['class1', 'class2', 'class3', 'class4', 'class5', 'class6', 'class7', 'class8', 'class9']\n",
    "dfsub = pd.DataFrame(classes, columns=cols)\n",
    "dfsub.insert(0,'ID',range(len(dfsub.class1)))\n",
    "dfsub.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfsub.to_csv('gene.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
